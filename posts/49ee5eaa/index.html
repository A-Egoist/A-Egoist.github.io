<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>TensorFlow实战——单变量线性回归 | A-Egoist</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="单变量线性回归概述单变量线性回归问题，因为其变量单一，因此，模型的搭建十分简单，拿来TensorFlow入门实战是最简单不过的了。 因为人工收集数据，再输入其中，比较麻烦，所以之间用随机数的方法生成人工数据集，来达到简化操作的目的。 生成人工数据集假设需要学习的函数为线性函数：y&#x3D;2x+1 导入库： 123456789# 在Jupyter中，使用 matplotlib 显示图像需要设置为 inli">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow实战——单变量线性回归">
<meta property="og:url" content="http://a-egoist.com/posts/49ee5eaa/index.html">
<meta property="og:site_name" content="A-Egoist">
<meta property="og:description" content="单变量线性回归概述单变量线性回归问题，因为其变量单一，因此，模型的搭建十分简单，拿来TensorFlow入门实战是最简单不过的了。 因为人工收集数据，再输入其中，比较麻烦，所以之间用随机数的方法生成人工数据集，来达到简化操作的目的。 生成人工数据集假设需要学习的函数为线性函数：y&#x3D;2x+1 导入库： 123456789# 在Jupyter中，使用 matplotlib 显示图像需要设置为 inli">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(1).png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(2).png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(3).png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(4).png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(5).png">
<meta property="article:published_time" content="2020-03-07T12:08:38.000Z">
<meta property="article:modified_time" content="2020-03-07T12:09:11.880Z">
<meta property="article:author" content="Amonologue">
<meta property="article:tag" content="实践">
<meta property="article:tag" content="笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(1).png">
  
    <link rel="alternate" href="/atom.xml" title="A-Egoist" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">A-Egoist</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://a-egoist.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-TensorFlow实战——单变量线性回归" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/posts/49ee5eaa/" class="article-date">
  <time datetime="2020-03-07T12:08:38.000Z" itemprop="datePublished">2020-03-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>►<a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow/">TensorFlow</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow实战——单变量线性回归
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="单变量线性回归"><a href="#单变量线性回归" class="headerlink" title="单变量线性回归"></a>单变量线性回归</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>单变量线性回归问题，因为其变量单一，因此，模型的搭建十分简单，拿来TensorFlow入门实战是最简单不过的了。</p>
<p>因为人工收集数据，再输入其中，比较麻烦，所以之间用随机数的方法生成人工数据集，来达到简化操作的目的。</p>
<h3 id="生成人工数据集"><a href="#生成人工数据集" class="headerlink" title="生成人工数据集"></a>生成人工数据集</h3><p>假设需要学习的函数为线性函数：y=2x+1</p>
<p>导入库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Jupyter中，使用 matplotlib 显示图像需要设置为 inline 模式，否则不会显示图像</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 载入matplotlib</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 载入numpy</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># 载入TensorFlow</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机数种子</span></span><br><span class="line">np.random.seed(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>生成随机数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#直接采用np生成等差数列的方法，生成100个点，每个点取值在-1~1之间</span></span><br><span class="line">x_data=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#y=2x+1+噪声，其中，噪声的维度与x_data一致</span></span><br><span class="line">y_data=<span class="number">2</span>*x_data+<span class="number">1.0</span>+np.random.randn(*x_data.shape)*<span class="number">0.4</span></span><br></pre></td></tr></table></figure>

<p>画出生成的散点和目标线性函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 画出随机生成数据的散点图</span></span><br><span class="line"></span><br><span class="line">plt.scatter(x_data,y_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出想要通过学习得到的目标线性函数y=2x+1</span></span><br><span class="line"></span><br><span class="line">plt.plot(x_data,<span class="number">1.0</span>+<span class="number">2</span>*x_data,color=<span class="string">&quot;red&quot;</span>,linewidth=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(1).png"></p>
<h3 id="构建线性模型"><a href="#构建线性模型" class="headerlink" title="构建线性模型"></a>构建线性模型</h3><p>定义x和y的占位符：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义训练数据的占位符，x是特征值，y是标签值</span></span><br><span class="line"></span><br><span class="line">x=tf.placeholder(<span class="string">&quot;float&quot;</span>,name=<span class="string">&quot;x&quot;</span>)</span><br><span class="line">y=tf.placeholder(<span class="string">&quot;float&quot;</span>,name=<span class="string">&quot;y&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>构建回归模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span>(<span class="params">x,w,b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.multiply(x,w)+b</span><br></pre></td></tr></table></figure>

<p>创建变量</p>
<ul>
<li>TensorFlow变量的声明函数是tf.Variable</li>
<li>tf.Variable的作用是保存和更新参数</li>
<li>变量的初始值可以是随机数、常数、或是通过其他变量的初始值计算得到</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建线性函数的斜率，变量w</span></span><br><span class="line">w=tf.Variable(<span class="number">1.0</span>,name=<span class="string">&quot;wO&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建线性函数的截距，变量b</span></span><br><span class="line">b=tf.Variable(<span class="number">0.0</span>,name=<span class="string">&quot;bO&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>预测值表示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pred是预测值，前向计算</span></span><br><span class="line">pred=model(x,w,b)</span><br></pre></td></tr></table></figure>

<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>设置训练参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 迭代次数(训练轮数)</span></span><br><span class="line">train_epochs=<span class="number">10</span></span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learning_rate=<span class="number">0.05</span></span><br><span class="line"><span class="comment"># 控制显示loss值的粒度</span></span><br><span class="line">display_step=<span class="number">10</span></span><br></pre></td></tr></table></figure>

<h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><ul>
<li>损失函数用于描述预测值与真实值之间的误差，从而指导模型收敛方向</li>
<li>常见损失函数：均方差和交叉熵</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 采用均方差作为损失函数</span></span><br><span class="line">loss_function=tf.reduce_mean(tf.square(y-pred))</span><br></pre></td></tr></table></figure>

<h3 id="定义优化器、定义最小化损失函数"><a href="#定义优化器、定义最小化损失函数" class="headerlink" title="定义优化器、定义最小化损失函数"></a>定义优化器、定义最小化损失函数</h3><p>选择优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 梯度下降优化器</span></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)</span><br></pre></td></tr></table></figure>

<h3 id="执行训练"><a href="#执行训练" class="headerlink" title="执行训练"></a>执行训练</h3><p>声明会话：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess=tf.Session()</span><br></pre></td></tr></table></figure>

<p>变量初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init=tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>

<p>训练开始：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练，轮数为 epoch，采用SGD随机梯度下降优化方法</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(train_epochs):</span><br><span class="line">    <span class="keyword">for</span> xs,ys <span class="keyword">in</span> <span class="built_in">zip</span>(x_data,y_data):</span><br><span class="line">        _,loss=sess.run([optimizer,loss_function],feed_dict=&#123;x: xs,y: ys&#125;)</span><br><span class="line">    bOtemp=b.<span class="built_in">eval</span>(session=sess)</span><br><span class="line">    wOtemp=w.<span class="built_in">eval</span>(session=sess)</span><br><span class="line">    plt.plot(x_data,wOtemp*x_data+bOtemp)<span class="comment"># 画图</span></span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(2).png"></p>
<h3 id="训练结果的可视化"><a href="#训练结果的可视化" class="headerlink" title="训练结果的可视化"></a>训练结果的可视化</h3><p>输出w和b：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;w:&quot;</span>,sess.run(w))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;b:&quot;</span>,sess.run(b))</span><br></pre></td></tr></table></figure>

<p>可视化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(x_data,y_data,label=<span class="string">&quot;Original data&quot;</span>)</span><br><span class="line">plt.plot(x_data,x_data*sess.run(w)+sess.run(b),label=<span class="string">&quot;Fitted line&quot;</span>,color=<span class="string">&quot;r&quot;</span>,linewidth=<span class="number">3</span>)</span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(3).png"></p>
<h3 id="利用学习到的模型进行预测"><a href="#利用学习到的模型进行预测" class="headerlink" title="利用学习到的模型进行预测"></a>利用学习到的模型进行预测</h3><p>预测方法一：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_test=<span class="number">3.21</span></span><br><span class="line"></span><br><span class="line">predict=sess.run(pred,feed_dict=&#123;x:x_test&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值：%f&quot;</span>%predict)</span><br><span class="line"></span><br><span class="line">target=<span class="number">2</span>*x_test+<span class="number">1.0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;目标值：%f&quot;</span>%target)</span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<blockquote>
<p>预测值：7.405184 </p>
<p>目标值：7.420000</p>
</blockquote>
<p>预测方法二：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_test=<span class="number">3.21</span></span><br><span class="line">predict=sess.run(w)*x_test+sess.run(b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值：%f&quot;</span>%predict)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>预测值：7.405184</p>
</blockquote>
<h3 id="显示loss的训练"><a href="#显示loss的训练" class="headerlink" title="显示loss的训练"></a>显示loss的训练</h3><p>训练方式和前面的训练方式相同，只是在训练的工程中输出loss，具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练，轮数为 epoch，采用SGD随机梯度下降优化方法</span></span><br><span class="line">step=<span class="number">0</span> <span class="comment"># 记录训练步数 </span></span><br><span class="line">loss_list=[] <span class="comment"># 用于保存loss值的列表</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(train_epochs):</span><br><span class="line">    <span class="keyword">for</span> xs,ys <span class="keyword">in</span> <span class="built_in">zip</span>(x_data,y_data):</span><br><span class="line">        _,loss=sess.run([optimizer,loss_function],feed_dict=&#123;x: xs,y: ys&#125;)</span><br><span class="line">        <span class="comment"># 显示损失值 loss</span></span><br><span class="line">        <span class="comment"># display_step: 控制报告粒度</span></span><br><span class="line">        <span class="comment"># 例如，如果display_step设为2，则将每训练2个样本输出一次损失值</span></span><br><span class="line">        <span class="comment"># 与超参数不同，修改display_step不会更改模型所学习的规律</span></span><br><span class="line">        loss_list.append(loss)</span><br><span class="line">        step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> step%display_step==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Train Epoch:&quot;</span>,<span class="string">&quot;%02d&quot;</span>%(epoch+<span class="number">1</span>),<span class="string">&quot;step:%03d&quot;</span>%(step),<span class="string">&quot;loss=&quot;</span>,\</span><br><span class="line">                 <span class="string">&quot;&#123;:.9f&#125;&quot;</span>.<span class="built_in">format</span>(loss))</span><br><span class="line"></span><br><span class="line">    bOtemp=b.<span class="built_in">eval</span>(session=sess)</span><br><span class="line">    wOtemp=w.<span class="built_in">eval</span>(session=sess)</span><br><span class="line">    plt.plot(x_data,wOtemp*x_data+bOtemp)<span class="comment"># 画图</span></span><br></pre></td></tr></table></figure>

<p>显示loss图（1）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(loss_list)</span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(4).png"></p>
<p>显示loss图（2）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(loss_list,<span class="string">&quot;g2&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagestensdan(5).png"></p>
<p>输出异常点：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x <span class="keyword">for</span> x <span class="keyword">in</span> loss_list <span class="keyword">if</span> x&gt;<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>输出展示：</p>
<blockquote>
<p>[1.0133754, 1.2284044, 1.0088208, 1.2116321, 2.3539772, 2.3148305, 1.3175836, 1.0387748, 1.5018207, 1.547514, 1.5513999, 1.5517284, 1.5517554, 1.5517581, 1.5517581, 1.5517581, 1.5517581]</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://a-egoist.com/posts/49ee5eaa/" data-id="ckw68jflm000sbgid210rbkm0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/posts/e831759b/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          TensorFlow实战——多变量线性回归
        
      </div>
    </a>
  
  
    <a href="/posts/24058a9b/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">爬虫入门(二)</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/">ACM</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95/">算法</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/%E7%AE%97%E6%B3%95/">算法</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hello/">Hello</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Log/">Log</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Parallel-Computing/">Parallel Computing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/%E7%88%AC%E8%99%AB/">爬虫</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/STL/">STL</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/STL/C/">C++</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/">刷题记录</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/ACM/">ACM</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/ACM/%E7%AE%97%E6%B3%95/">算法</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/SQL/">SQL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB/">爬虫</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB/Python/">Python</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E7%AE%97%E6%B3%95/">数据结构及算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E8%AE%BA/">数论</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow/">TensorFlow</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%80%92%E6%8E%A8/">递推</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BFS/" rel="tag">BFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BeautifulSoup%E5%BA%93/" rel="tag">BeautifulSoup库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LaTex/" rel="tag">LaTex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/String/" rel="tag">String</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hdu/" rel="tag">hdu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/random%E5%BA%93/" rel="tag">random库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/requests%E5%BA%93/" rel="tag">requests库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/time%E5%BA%93/" rel="tag">time库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/transformer/" rel="tag">transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wordcloud%E5%BA%93/" rel="tag">wordcloud库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%88%86/" rel="tag">二分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%8B%E7%BB%8D/" rel="tag">介绍</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C/" rel="tag">前缀和</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%9A%E5%BC%88/" rel="tag">博弈</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%BD%A2%E5%BA%93/" rel="tag">图形库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%83%E6%B0%8F%E7%AD%9B%E6%B3%95/" rel="tag">埃氏筛法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E7%A1%80/" rel="tag">基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%AE%E5%88%86/" rel="tag">差分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%80%9D%E7%BB%B4/" rel="tag">思维</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E8%AE%BA/" rel="tag">数论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%BF%97/" rel="tag">日志</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%91/" rel="tag">树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AC%A7%E6%8B%89%E7%AD%9B%E6%B3%95/" rel="tag">欧拉筛法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%8B%E8%AF%95/" rel="tag">测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E5%88%92/" rel="tag">计划</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B4%AA%E5%BF%83/" rel="tag">贪心</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%94%99%E6%8E%92%E5%85%AC%E5%BC%8F/" rel="tag">错排公式</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/BFS/" style="font-size: 10px;">BFS</a> <a href="/tags/BeautifulSoup%E5%BA%93/" style="font-size: 10px;">BeautifulSoup库</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CUDA/" style="font-size: 10px;">CUDA</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/LaTex/" style="font-size: 10px;">LaTex</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/String/" style="font-size: 10px;">String</a> <a href="/tags/attention/" style="font-size: 10px;">attention</a> <a href="/tags/hdu/" style="font-size: 10px;">hdu</a> <a href="/tags/random%E5%BA%93/" style="font-size: 10px;">random库</a> <a href="/tags/requests%E5%BA%93/" style="font-size: 10px;">requests库</a> <a href="/tags/time%E5%BA%93/" style="font-size: 10px;">time库</a> <a href="/tags/transformer/" style="font-size: 10px;">transformer</a> <a href="/tags/wordcloud%E5%BA%93/" style="font-size: 10px;">wordcloud库</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 10px;">二分</a> <a href="/tags/%E4%BB%8B%E7%BB%8D/" style="font-size: 10px;">介绍</a> <a href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C/" style="font-size: 12.5px;">前缀和</a> <a href="/tags/%E5%8D%9A%E5%BC%88/" style="font-size: 10px;">博弈</a> <a href="/tags/%E5%9B%BE%E5%BD%A2%E5%BA%93/" style="font-size: 10px;">图形库</a> <a href="/tags/%E5%9F%83%E6%B0%8F%E7%AD%9B%E6%B3%95/" style="font-size: 10px;">埃氏筛法</a> <a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 17.5px;">基础</a> <a href="/tags/%E5%AE%9E%E8%B7%B5/" style="font-size: 15px;">实践</a> <a href="/tags/%E5%B7%AE%E5%88%86/" style="font-size: 10px;">差分</a> <a href="/tags/%E6%80%9D%E7%BB%B4/" style="font-size: 10px;">思维</a> <a href="/tags/%E6%95%B0%E8%AE%BA/" style="font-size: 10px;">数论</a> <a href="/tags/%E6%97%A5%E5%BF%97/" style="font-size: 10px;">日志</a> <a href="/tags/%E6%A0%91/" style="font-size: 10px;">树</a> <a href="/tags/%E6%AC%A7%E6%8B%89%E7%AD%9B%E6%B3%95/" style="font-size: 10px;">欧拉筛法</a> <a href="/tags/%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">测试</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 20px;">笔记</a> <a href="/tags/%E8%AE%A1%E5%88%92/" style="font-size: 10px;">计划</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 10px;">贪心</a> <a href="/tags/%E9%94%99%E6%8E%92%E5%85%AC%E5%BC%8F/" style="font-size: 10px;">错排公式</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/posts/b68f41a0/">算法竞赛进阶指南学习笔记</a>
          </li>
        
          <li>
            <a href="/posts/374e1302/">数学知识</a>
          </li>
        
          <li>
            <a href="/posts/43934f6d/">搜索</a>
          </li>
        
          <li>
            <a href="/posts/b8859ab5/">二维前缀和</a>
          </li>
        
          <li>
            <a href="/posts/fc45aa12/">SQL Sever 学习笔记——图形化创建数据库</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Amonologue<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>