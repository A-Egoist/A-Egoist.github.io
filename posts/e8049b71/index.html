<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>MNIST手写数字识别的两种实现方法 | A-Egoist</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="简介​        当我们学习编程语言时， 第一课通常会学习一个简单的 “Hello World” 程序，而 MNIST 手写字符识别可以算得上是机器学习界的 “Hello World“ 。MNIST 是由 Yann LeCun 等人建立的一个手写字符数据集。它简单易用，是一个很好的入门范例。 ​        在MNIST数据集中有两类图像：一类是训练图像（对应文件 train-images-">
<meta property="og:type" content="article">
<meta property="og:title" content="MNIST手写数字识别的两种实现方法">
<meta property="og:url" content="http://a-egoist.com/posts/e8049b71/index.html">
<meta property="og:site_name" content="A-Egoist">
<meta property="og:description" content="简介​        当我们学习编程语言时， 第一课通常会学习一个简单的 “Hello World” 程序，而 MNIST 手写字符识别可以算得上是机器学习界的 “Hello World“ 。MNIST 是由 Yann LeCun 等人建立的一个手写字符数据集。它简单易用，是一个很好的入门范例。 ​        在MNIST数据集中有两类图像：一类是训练图像（对应文件 train-images-">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagesMNIST_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagesMNIST_2.png">
<meta property="article:published_time" content="2020-03-13T14:28:08.000Z">
<meta property="article:modified_time" content="2020-03-13T14:37:50.838Z">
<meta property="article:author" content="Amonologue">
<meta property="article:tag" content="实践">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="MNIST">
<meta property="article:tag" content="CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagesMNIST_1.png">
  
    <link rel="alternate" href="/atom.xml" title="A-Egoist" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">A-Egoist</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://a-egoist.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-MNIST手写数字识别的多种方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/posts/e8049b71/" class="article-date">
  <time datetime="2020-03-13T14:28:08.000Z" itemprop="datePublished">2020-03-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>►<a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow/">TensorFlow</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      MNIST手写数字识别的两种实现方法
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​        当我们学习编程语言时， 第一课通常会学习一个简单的 <code>“Hello World”</code> 程序，而<code> MNIST 手写字符识别</code>可以算得上是机器学习界的 <code>“Hello World“ </code>。MNIST 是由 Yann LeCun 等人建立的一个手写字符数据集。它简单易用，是一个很好的入门范例。</p>
<p>​        在<code>MNIST</code>数据集中有两类图像：一类是训练图像（对应文件 <code>train-images-idx3-ubyte.gz</code> 和 <code>train-labels-idxl-ubyte.gz</code> ），另一类是测试图像（对应文件 <code>t10k-images-idx3-ubyte.gz</code> 和 <code>tl0k-labels-idxl-ubyte.gz</code> ）。 训练图像一共有60000张，供研究人员训练出合适的模型。测试图像一共有10000张，供研究人员测试训练的模型的性能 。</p>
<h2 id="Softmax回归实现MNIST手写数字识别-accuracy≈0-91"><a href="#Softmax回归实现MNIST手写数字识别-accuracy≈0-91" class="headerlink" title="Softmax回归实现MNIST手写数字识别(accuracy≈0.91)"></a><code>Softmax</code>回归实现MNIST手写数字识别(accuracy≈0.91)</h2><h3 id="1、Softmax回归的原理"><a href="#1、Softmax回归的原理" class="headerlink" title="1、Softmax回归的原理"></a>1、<code>Softmax</code>回归的原理</h3><p>​        <code>Softmax</code>回归是一个线性的多类分类模型，实际上白是直接从 <code>Logistic</code> 回归模型转化而来的。区别在于 <code>Logistic</code> 回归模型为两类分类模型，而 <code>Softmax</code>模型为多类分类模型。<br>​        在手写体识别问题中 ，一共有 10 个类别（ 0~ 9 ），我们希望对输入的图像计算白属于每个类别的概率。如属于 9 的概率为 70% ，属于 1 的概率为 10%等。最后模型预测的结果就是概率最大的那个类别。</p>
<p>​        <code>Softmax</code>函数的定义：<img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagesMNIST_1.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/A-Egoist/Blog-Figure-bed/imagesMNIST_2.png"></p>
<h3 id="Softmax回归在Tensorflow中的实现"><a href="#Softmax回归在Tensorflow中的实现" class="headerlink" title="Softmax回归在Tensorflow中的实现"></a><code>Softmax</code>回归在<code>Tensorflow</code>中的实现</h3><p>1）首先导入<code>TensorFlow</code>模块，并且导入数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">&#x27;MNIST_data&#x27;</span>,one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<blockquote>
<p>Extracting MNIST_data\train-images-idx3-ubyte.gz </p>
<p>Extracting MNIST_data\train-labels-idx1-ubyte.gz </p>
<p>Extracting MNIST_data\t10k-images-idx3-ubyte.gz </p>
<p>Extracting MNIST_data\t10k-labels-idx1-ubyte.gz</p>
</blockquote>
<p>2）创建占位符、定义变量、设定输出模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#x、y为占位符，其中x代表识别的图像输入，y代表图像实际的标签(label)</span></span><br><span class="line">x=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">y=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line"><span class="comment">#w是一个变量，在训练过程中根据损失来自动改变大小</span></span><br><span class="line">w=tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line"><span class="comment">#b是偏置项(biases)</span></span><br><span class="line">b=tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line">pred=tf.nn.softmax(tf.matmul(x,w)+b)</span><br></pre></td></tr></table></figure>

<p>3）定义交叉熵、定义优化器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy=tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred)))</span><br><span class="line"><span class="comment">#利用梯度下降法对模型的参数(w,b)进行优化、调节</span></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>

<p>4）创建会话、初始化变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#因为之前的定义都是节点，而在TensorFlow中，需要构建会话Session才能让这个模型动起来</span></span><br><span class="line"><span class="comment">#在这个过程中传递张量进行运算</span></span><br><span class="line">sess=tf.Session()</span><br><span class="line"><span class="comment">#初始化之前出现的所有变量</span></span><br><span class="line">init=tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>

<p>5）优化w、b变量（对model进行训练）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):<span class="comment">#进行1000步梯度下降</span></span><br><span class="line">    xs,ys=mnist.train.next_batch(<span class="number">100</span>)<span class="comment">#从mnist.train中提取100个训练数据</span></span><br><span class="line">    <span class="comment">#在Session中运行优化器(optimizer)，运行时要传入占位符的值</span></span><br><span class="line">    sess.run(optimizer,feed_dict=&#123;x:xs,y:ys&#125;)</span><br></pre></td></tr></table></figure>

<p>6）检测模型的训练结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#正确的预测结果</span></span><br><span class="line">correct_prediction=tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#计算预测准确率，它们都是Tensor</span></span><br><span class="line">accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line"><span class="comment">#在Session中运行Tensor的值可以得到Tensor</span></span><br><span class="line"><span class="built_in">print</span>(sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>

<p>最后的结果输出：</p>
<blockquote>
<p>0.9194</p>
</blockquote>
<h3 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h3><p>在第(6)部分，我们传入的是测试值，运行结果为0.9194，也就是说我们的手写字体的识别率只有91.94%，这里的预测准确率并不高。因此我将试着用CNN(卷积神经网络)来实现MNIST手写数字的识别，正确率可以达到99%。</p>
<h2 id="两层卷积网络实现分类"><a href="#两层卷积网络实现分类" class="headerlink" title="两层卷积网络实现分类"></a>两层卷积网络实现分类</h2><h3 id="1、什么是CNN-卷积神经网络"><a href="#1、什么是CNN-卷积神经网络" class="headerlink" title="1、什么是CNN(卷积神经网络)"></a>1、什么是CNN(卷积神经网络)</h3><p>因为篇幅原因，本文不在这里讲解CNN的定义和基本模型，如果想要了解CNN原理的可以看看这些资料：</p>
<p><a target="_blank" rel="noopener" href="https://classroom.udacity.com/courses/ud730/lessons/6377263405/concepts/63796332430923">Google官方卷积神经网络介绍视频</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/103620235">卷积神经网络CNN原理详解及TensorFlow编写CNN</a></p>
<h3 id="2、卷积实现分类"><a href="#2、卷积实现分类" class="headerlink" title="2、卷积实现分类"></a>2、卷积实现分类</h3><p>1）同样的和之前一样导入模块、导入数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">&quot;MNIST_data/&quot;</span>,one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<blockquote>
<p>Extracting MNIST_data/train-images-idx3-ubyte.gz </p>
<p>Extracting MNIST_data/train-labels-idx1-ubyte.gz </p>
<p>Extracting MNIST_data/t10k-images-idx3-ubyte.gz </p>
<p>Extracting MNIST_data/t10k-labels-idx1-ubyte.gz</p>
</blockquote>
<p>2）定义占位符，与上文相同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">y=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<p>3）从这步开始与上面开始有了差异。因为这一次使用的是卷积神经网络对图像进行分类，所以我们不能再使用784维的向量来表示输入的x，而是将其还原成28*28的图像形式。[-1,28,28,1]中的-1表示形状第一维的大小是根据x自动确定的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将单张图片从784维向量重新还原为28x28的矩阵图片</span></span><br><span class="line">x_image=tf.reshape(x,[-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>4）定义卷积层的构造函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(tf.truncated_normal(shape,stddev=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(tf.constant(<span class="number">0.1</span>,shape=shape))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params">x,w</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x,w,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>5）第一个卷积层</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一卷积层</span></span><br><span class="line">w_conv1=weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>])</span><br><span class="line">b_conv1=bias_variable([<span class="number">32</span>])</span><br><span class="line">h_conv1=tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)</span><br><span class="line">h_pool1=max_pool_2x2(h_conv1)</span><br></pre></td></tr></table></figure>

<p>6）第二个卷积层</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第二卷积层</span></span><br><span class="line">w_conv2=weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>])</span><br><span class="line">b_conv2=bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2=tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)</span><br><span class="line">h_pool2=max_pool_2x2(h_conv2)</span><br></pre></td></tr></table></figure>

<p>7）第一个全连接层，并且加入了Dropout，防止神经网络<a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/103595096">过拟合</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全连接层  输出1024维的向量</span></span><br><span class="line">w_fc1=weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">1024</span>])</span><br><span class="line">b_fc1=bias_variable([<span class="number">1024</span>])</span><br><span class="line">h_pool2_flat=tf.reshape(h_pool2,[-<span class="number">1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,w_fc1)+b_fc1)</span><br><span class="line"></span><br><span class="line">keep_prob=tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob)</span><br></pre></td></tr></table></figure>

<p>8）第二个全连接层，因为上一个全连接层将输出变成了1024维的向量，由于这是一个分类问题，我们需要让这个输出变为对10个类别的概率预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w_fc2=weight_variable([<span class="number">1024</span>,<span class="number">10</span>])</span><br><span class="line">b_fc2=bias_variable([<span class="number">10</span>])</span><br><span class="line">y_conv=tf.matmul(h_fc1_drop,w_fc2)+b_fc2</span><br></pre></td></tr></table></figure>

<p>9）<code>y_conv</code> 相当于 <code>Softmax</code> 模型中的 <code>Logit</code>，当然可以使用 <code>Softmax</code> 函数将其转换为10个类别的概率，再定义交叉熵损失。但其实<code>TensorFlow</code>提供了 一个更直接的<code>tf.nn.softmax_cross_ entropy_ with _logits</code>函数，它可以直接对<code>Logit</code>定义交叉熵损失，写法为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_conv))</span><br><span class="line"></span><br><span class="line">optimizer=tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>

<p>10）定义测试结果的准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">correct_prediction=tf.equal(tf.argmax(y_conv,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br></pre></td></tr></table></figure>

<p>11）训练过程与之前一样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建Session，对变量初始化</span></span><br><span class="line">sess=tf.InteractiveSession()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练2000步，根据需要自由调整</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2000</span>):</span><br><span class="line">    batch=mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        train_accuracy=accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x:batch[<span class="number">0</span>],y:batch[<span class="number">1</span>],keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;step %d, training accuracy %g&#x27;</span>%(i,train_accuracy))</span><br><span class="line">        </span><br><span class="line">    optimizer.run(feed_dict=&#123;x:batch[<span class="number">0</span>],y:batch[<span class="number">1</span>],keep_prob:<span class="number">0.5</span>&#125;)</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<blockquote>
<p>step 0, training accuracy 0.14 </p>
<p>step 100, training accuracy 0.86</p>
<p>…</p>
<p>step 1900, training accuracy 0.98</p>
</blockquote>
<p>12）训练结束后，输出在全体测试集上的准确率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test accuracy %g&#x27;</span>%accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels,keep_prob:<span class="number">1.0</span>&#125;))</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<blockquote>
<p>test accuracy 0.9739</p>
</blockquote>
<p>13）在经过多次调参之后，得到的最高的accuracy=0.9891.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://a-egoist.com/posts/e8049b71/" data-id="ckw68jflg000hbgidc64j4isw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/posts/c7e65d0f/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          素数筛法(转载+总结)
        
      </div>
    </a>
  
  
    <a href="/posts/7de3b458/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">MNIST手写数字识别入门</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/">ACM</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95/">算法</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ACM/%E7%AE%97%E6%B3%95/">算法</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hello/">Hello</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Log/">Log</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Parallel-Computing/">Parallel Computing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/%E7%88%AC%E8%99%AB/">爬虫</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/STL/">STL</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/STL/C/">C++</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/">刷题记录</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/ACM/">ACM</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/ACM/%E7%AE%97%E6%B3%95/">算法</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/SQL/">SQL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB/">爬虫</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB/Python/">Python</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E7%AE%97%E6%B3%95/">数据结构及算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E8%AE%BA/">数论</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow/">TensorFlow</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%80%92%E6%8E%A8/">递推</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BFS/" rel="tag">BFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BeautifulSoup%E5%BA%93/" rel="tag">BeautifulSoup库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LaTex/" rel="tag">LaTex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/" rel="tag">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/String/" rel="tag">String</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hdu/" rel="tag">hdu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/random%E5%BA%93/" rel="tag">random库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/requests%E5%BA%93/" rel="tag">requests库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/time%E5%BA%93/" rel="tag">time库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/transformer/" rel="tag">transformer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wordcloud%E5%BA%93/" rel="tag">wordcloud库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%88%86/" rel="tag">二分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%8B%E7%BB%8D/" rel="tag">介绍</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C/" rel="tag">前缀和</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%9A%E5%BC%88/" rel="tag">博弈</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%BD%A2%E5%BA%93/" rel="tag">图形库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%83%E6%B0%8F%E7%AD%9B%E6%B3%95/" rel="tag">埃氏筛法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E7%A1%80/" rel="tag">基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%AE%E5%88%86/" rel="tag">差分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%80%9D%E7%BB%B4/" rel="tag">思维</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E8%AE%BA/" rel="tag">数论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%BF%97/" rel="tag">日志</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%91/" rel="tag">树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AC%A7%E6%8B%89%E7%AD%9B%E6%B3%95/" rel="tag">欧拉筛法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%8B%E8%AF%95/" rel="tag">测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E5%88%92/" rel="tag">计划</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B4%AA%E5%BF%83/" rel="tag">贪心</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%94%99%E6%8E%92%E5%85%AC%E5%BC%8F/" rel="tag">错排公式</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/BFS/" style="font-size: 10px;">BFS</a> <a href="/tags/BeautifulSoup%E5%BA%93/" style="font-size: 10px;">BeautifulSoup库</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CUDA/" style="font-size: 10px;">CUDA</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/LaTex/" style="font-size: 10px;">LaTex</a> <a href="/tags/MNIST/" style="font-size: 10px;">MNIST</a> <a href="/tags/String/" style="font-size: 10px;">String</a> <a href="/tags/attention/" style="font-size: 10px;">attention</a> <a href="/tags/hdu/" style="font-size: 10px;">hdu</a> <a href="/tags/random%E5%BA%93/" style="font-size: 10px;">random库</a> <a href="/tags/requests%E5%BA%93/" style="font-size: 10px;">requests库</a> <a href="/tags/time%E5%BA%93/" style="font-size: 10px;">time库</a> <a href="/tags/transformer/" style="font-size: 10px;">transformer</a> <a href="/tags/wordcloud%E5%BA%93/" style="font-size: 10px;">wordcloud库</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 10px;">二分</a> <a href="/tags/%E4%BB%8B%E7%BB%8D/" style="font-size: 10px;">介绍</a> <a href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C/" style="font-size: 12.5px;">前缀和</a> <a href="/tags/%E5%8D%9A%E5%BC%88/" style="font-size: 10px;">博弈</a> <a href="/tags/%E5%9B%BE%E5%BD%A2%E5%BA%93/" style="font-size: 10px;">图形库</a> <a href="/tags/%E5%9F%83%E6%B0%8F%E7%AD%9B%E6%B3%95/" style="font-size: 10px;">埃氏筛法</a> <a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 17.5px;">基础</a> <a href="/tags/%E5%AE%9E%E8%B7%B5/" style="font-size: 15px;">实践</a> <a href="/tags/%E5%B7%AE%E5%88%86/" style="font-size: 10px;">差分</a> <a href="/tags/%E6%80%9D%E7%BB%B4/" style="font-size: 10px;">思维</a> <a href="/tags/%E6%95%B0%E8%AE%BA/" style="font-size: 10px;">数论</a> <a href="/tags/%E6%97%A5%E5%BF%97/" style="font-size: 10px;">日志</a> <a href="/tags/%E6%A0%91/" style="font-size: 10px;">树</a> <a href="/tags/%E6%AC%A7%E6%8B%89%E7%AD%9B%E6%B3%95/" style="font-size: 10px;">欧拉筛法</a> <a href="/tags/%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">测试</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 20px;">笔记</a> <a href="/tags/%E8%AE%A1%E5%88%92/" style="font-size: 10px;">计划</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 10px;">贪心</a> <a href="/tags/%E9%94%99%E6%8E%92%E5%85%AC%E5%BC%8F/" style="font-size: 10px;">错排公式</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/posts/b68f41a0/">算法竞赛进阶指南学习笔记</a>
          </li>
        
          <li>
            <a href="/posts/374e1302/">数学知识</a>
          </li>
        
          <li>
            <a href="/posts/43934f6d/">搜索</a>
          </li>
        
          <li>
            <a href="/posts/b8859ab5/">二维前缀和</a>
          </li>
        
          <li>
            <a href="/posts/fc45aa12/">SQL Sever 学习笔记——图形化创建数据库</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Amonologue<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>